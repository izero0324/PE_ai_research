{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "correct-roulette",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd import Function\n",
    "from torchvision import models\n",
    "from torchvision import utils\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from model.drn import drn_d_54,drn_d_base\n",
    "from model.CBAM import drn_d_CBAM\n",
    "from torchvision import datasets, transforms\n",
    "import argparse\n",
    "import pydicom\n",
    "import torch.nn.functional as F \n",
    "import random\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.set_device(0)\n",
    "random.seed(3)\n",
    "\n",
    "class FeatureExtractor():\n",
    "    \"\"\" Class for extracting activations and \n",
    "    registering gradients from targetted intermediate layers \"\"\"\n",
    "    def __init__(self, model, target_layers):\n",
    "        self.model = model\n",
    "        self.target_layers = target_layers\n",
    "        self.gradients = []\n",
    "\n",
    "    def save_gradient(self, grad):\n",
    "    \tself.gradients.append(grad)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        outputs = []\n",
    "        self.gradients = []\n",
    "        out1 = x.to(device)\n",
    "        for name, module in self.model._modules.items():\n",
    "            #print(name)\n",
    "            if name == 'model':\n",
    "                out1 = module(out1)\n",
    "            #if name in ['conv1', 'conv2', 'conv3']: \n",
    "            #    x = F.max_pool2d(x, 2,2)\n",
    "            if name in self.target_layers:\n",
    "                print(name)\n",
    "                out1.register_hook(self.save_gradient)\n",
    "                outputs += [out1]\n",
    "        \n",
    "        return outputs, out1\n",
    "\n",
    "class ModelOutputs():\n",
    "\n",
    "    def __init__(self, model, target_layers):\n",
    "        self.model = model\n",
    "        self.feature_extractor = FeatureExtractor(self.model, 'model')\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(2)\n",
    "    def get_gradients(self):\n",
    "        return self.feature_extractor.gradients\n",
    "\n",
    "    def __call__(self, x):\n",
    "        target_activations, output  = self.feature_extractor(x)\n",
    "        \n",
    "        output = self.avgpool(output)\n",
    "        print(output.shape)\n",
    "        output = output.view(output.size(0), -1).to(device)\n",
    "        output = self.model.fc(output)\n",
    "        return target_activations, output\n",
    "\n",
    "def preprocess_image(img):\n",
    "    #print(img.shape)\n",
    "    preprocessed_img = img.copy()\n",
    "    #print(preprocessed_img.shape)\n",
    "    preprocessed_img = crop_center(img, 400, 400)\n",
    "    preprocessed_img = torch.from_numpy(preprocessed_img)\n",
    "    preprocessed_img.unsqueeze_(0).unsqueeze_(0)\n",
    "    input = Variable(preprocessed_img, requires_grad = True)\n",
    "    #print(input.shape)\n",
    "    return input\n",
    "\n",
    "def crop_center(img,cropx,cropy):\n",
    "    x,y = img.shape\n",
    "    startx = x//2 - cropx//2\n",
    "    starty = y//2 - cropy//2    \n",
    "    return img[startx:startx+cropx, starty:starty+cropy]\n",
    "import os\n",
    "def show_cam_on_image(img, mask, i, pred):\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255*mask), cv2.COLORMAP_JET)\n",
    "    heatmap = np.float32(heatmap) / 255\n",
    "    #print(img.shape)\n",
    "    img = np.transpose(img,(1,2,0))\n",
    "    cam = heatmap + np.float32(img)\n",
    "    cam = cam / np.max(cam)\n",
    "    name = i.split('.')[0].split('/')[-1]\n",
    "    \n",
    "    #file_name = os.path.join('0_1', name)\n",
    "    \n",
    "    file_name = os.path.join('sample/base/', name)\n",
    "    print(file_name)\n",
    "    cv2.imwrite(file_name + '_dicom.png', np.uint8(255 * img))\n",
    "    \n",
    "    cv2.imwrite(file_name +'_'+ name + \"_cam.jpg\", np.uint8(255 * cam))\n",
    "\n",
    "class GradCam:\n",
    "    def __init__(self, model, target_layer_names):\n",
    "        self.model = model\n",
    "        self.model.eval()  \n",
    "        self.extractor = ModelOutputs(self.model, target_layer_names)  \n",
    "    def forward(self, input):\n",
    "        return self.model(input)   \n",
    "    def __call__(self, input, index = None):\n",
    "        \n",
    "        features, output = self.extractor(input)     \n",
    "        if index == None:\n",
    "            index = np.argmax(output.cpu().data.numpy())        \n",
    "        one_hot = np.zeros((1, output.size()[-1]), dtype = np.float32)\n",
    "        one_hot[0][index] = 1\n",
    "        one_hot = Variable(torch.from_numpy(one_hot), requires_grad = True)\n",
    "        \n",
    "        one_hot = torch.sum(one_hot.to(device) * output)     \n",
    "        self.model.model.zero_grad()\n",
    "        self.model.fc.zero_grad()\n",
    "        one_hot.backward()\n",
    "        #print(len(self.extractor.get_gradients()))\n",
    "        grads_val = self.extractor.get_gradients()[-1].cpu().data.numpy()        \n",
    "        target = features[-1]\n",
    "        target = target.cpu().data.numpy()[0, :]\n",
    "        #print(target.shape)\n",
    "        weights = grads_val[0, :]\n",
    "        #weights = np.mean(grads_val, axis = (2, 3))[0, :]\n",
    "        cam = np.zeros(target.shape[1 : ], dtype = np.float32)       \n",
    "        for i, w in enumerate(weights):\n",
    "        \tcam += w * target[i, :, :]     \n",
    "        cam = np.maximum(cam, 0)\n",
    "        cam = cv2.resize(cam, (400, 400))\n",
    "        cam = cam - np.min(cam)\n",
    "        cam = cam / np.max(cam)\n",
    "        return cam\n",
    "\n",
    "class GuidedBackpropReLU(Function):\n",
    "\n",
    "    def forward(self, input):\n",
    "        positive_mask = (input > 0).type_as(input)\n",
    "        output = torch.addcmul(torch.zeros(input.size()).type_as(input), input, positive_mask)\n",
    "        self.save_for_backward(input, output)\n",
    "        return output\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        input, output = self.saved_tensors\n",
    "        grad_input = None\n",
    "\n",
    "        positive_mask_1 = (input > 0).type_as(grad_output)\n",
    "        positive_mask_2 = (grad_output > 0).type_as(grad_output)\n",
    "        grad_input = torch.addcmul(torch.zeros(input.size()).type_as(input), torch.addcmul(torch.zeros(input.size()).type_as(input), grad_output, positive_mask_1), positive_mask_2)\n",
    "\n",
    "        return grad_input\n",
    "\n",
    "class GuidedBackpropReLUModel:\n",
    "\tdef __init__(self, model):\n",
    "\t\tself.model = model\n",
    "\t\tself.model.eval()\n",
    "\t\t\n",
    "\n",
    "\t\t# replace ReLU with GuidedBackpropReLU\n",
    "\t\tfor idx, module in self.model.model._modules.items():\n",
    "\t\t\tif module.__class__.__name__ == 'relu':\n",
    "\t\t\t\tself.model.features._modules[idx] = GuidedBackpropReLU()\n",
    "\n",
    "\tdef forward(self, input):\n",
    "\t\treturn self.model(input)\n",
    "\n",
    "\tdef __call__(self, input, index = None):\n",
    "\t\t\n",
    "\t\toutput = self.forward(input.to(device))\n",
    "\n",
    "\t\tif index == None:\n",
    "\t\t\tindex = np.argmax(output.cpu().data.numpy())\n",
    "\n",
    "\t\tone_hot = np.zeros((1, output.size()[-1]), dtype = np.float32)\n",
    "\t\tone_hot[0][index] = 1\n",
    "\t\tone_hot = Variable(torch.from_numpy(one_hot), requires_grad = True)\n",
    "\t\t\n",
    "\t\tone_hot = torch.sum(one_hot.to(device) * output)\n",
    "\n",
    "\t\t# self.model.features.zero_grad()\n",
    "\t\t# self.model.classifier.zero_grad()\n",
    "\t\tone_hot.backward()\n",
    "\n",
    "\t\toutput = input.grad.cpu().data.numpy()\n",
    "\t\toutput = output[0,:,:,:]\n",
    "\n",
    "\t\treturn output\n",
    "\n",
    "\n",
    "\n",
    "class CNNX(nn.Module):\n",
    "    \n",
    "    def __init__(self, backbone = 'drn', out_stride = 16, num_class = 2):\n",
    "        super(CNNX, self).__init__()\n",
    "        \n",
    "        if backbone == 'drn':\n",
    "            output_stride = 8\n",
    "        #self.drn = drn_d_base(nn.BatchNorm2d)\n",
    "        #self.drn = gc_drn_54(nn.BatchNorm2d)\n",
    "        #self.model = mixnet_l()\n",
    "        #self.model = drn_d_CBAM(nn.BatchNorm2d)\n",
    "        self.model = drn_d_base(nn.BatchNorm2d)\n",
    "        #self.attention = A_net(512)\n",
    "        #self.conv_out = nn.Conv2d(512,2,1)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(2)\n",
    "        self._dropout = nn.Dropout(0.25)\n",
    "        #self.fc = nn.Linear(2048, 2)\n",
    "        self.fc = nn.Linear(2048, 2)\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.model(input)\n",
    "       #atten = self.attention(input)\n",
    "       #atten = torch.sigmoid(atten)\n",
    "       #x = torch.mul(x, atten)\n",
    "        #x = self.conv_out(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        #x = self._dropout(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def load_model(Net, optimizer, model_file):\n",
    "    assert os.path.exists(model_file),'There is no model file from'+model_file\n",
    "    checkpoint = torch.load(model_file, map_location='cuda:0')\n",
    "    Net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    start_epoch = checkpoint['epoch']+1\n",
    "    if optimizer is not None:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    return Net, optimizer, start_epoch\n",
    "\n",
    "class CNNX1(nn.Module):\n",
    "    \n",
    "    def __init__(self, backbone = 'drn', out_stride = 16, num_class = 2):\n",
    "        super(CNNX1, self).__init__()\n",
    "        \n",
    "        if backbone == 'drn':\n",
    "            output_stride = 8\n",
    "        #self.drn = drn_d_base(nn.BatchNorm2d)\n",
    "        #self.drn = gc_drn_54(nn.BatchNorm2d)\n",
    "        #self.model = mixnet_l()\n",
    "        self.model_d = drn_d_CBAM(nn.BatchNorm2d)\n",
    "        self.model_l = drn_d_CBAM(nn.BatchNorm2d)\n",
    "        #self.model_m = drn_d_CBAM(nn.BatchNorm2d)\n",
    "        #self.attention = A_net(512)\n",
    "        #self.conv_out = nn.Conv2d(512,2,1)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(2)\n",
    "        self._dropout = nn.Dropout(0.25)\n",
    "        #self.fc = nn.Linear(2048, 2)\n",
    "        self.fc = nn.Linear(4096, 2)\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, input_def, input_lung):\n",
    "        d = self.model_d(input_def)\n",
    "        d = self.avgpool(d)\n",
    "        l = self.model_l(input_lung)\n",
    "        l = self.avgpool(l)\n",
    "        #m = self.model_m(input_m)\n",
    "        #m = self.avgpool(m)\n",
    "        x = torch.cat((d.view(d.size(0), -1),\n",
    "                          l.view(l.size(0), -1)), dim=1)\n",
    "       #atten = self.attention(input)\n",
    "       #atten = torch.sigmoid(atten)\n",
    "       #x = torch.mul(x, atten)\n",
    "        #x = self.conv_out(x)\n",
    "        #x = self.avgpool(x)\n",
    "        #x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        x = self._dropout(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "square-somerset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Andrew/PE_research/log/savemodel/CT_class_dinamic_MV_drn_.pth loaded\n"
     ]
    }
   ],
   "source": [
    "net = CNNX1().to(device)\n",
    "#print(net.model)\n",
    "#net = CNNX().cpu()\n",
    "resume = '/home/ubuntu/Andrew/PE_research/log/savemodel/CT_class_dinamic_MV_drn_.pth'\n",
    "#resume = 'best_acc_142.pth'\n",
    "Net, _, _ = load_model(net, None, resume)\n",
    "print(resume,'loaded')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dried-settlement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Andrew/lung_datatset/test/noPE/19743272/1974327231.dcm\n",
      "torch.Size([1, 1, 2, 2])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [1 x 4], m2: [4096 x 2] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:283",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-44f9b0ee29b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# Otherwise, targets the requested index.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mtarget_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_cam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-90a93d0ea221>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input, index)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-90a93d0ea221>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtarget_activations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/anaconda3/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1608\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1609\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1610\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1611\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1612\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [1 x 4], m2: [4096 x 2] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:283"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "#folder_name = list(glob.glob('/home/mel/PE_research/opendata/*'))\n",
    "#\n",
    "#folder_name.remove('/home/mel/PE_research/opendata/1')\n",
    "##print(folder_name)\n",
    "#folder1_name = list(glob.glob('/home/mel/PE_research/opendata/1/*'))\n",
    "#\n",
    "#random.shuffle(folder_name)\n",
    "#random.shuffle(folder1_name)\n",
    "#valid_size = 0.2\n",
    "#test_size = 0.3\n",
    "#num_patient = len(folder_name)\n",
    "#num_patient1 = len(folder1_name)\n",
    "##print(folder_name)\n",
    "#num_patient = len(folder_name)\n",
    "#num_patient1 = len(folder1_name)\n",
    "#split = int(valid_size*num_patient)\n",
    "#split1 = int(valid_size*num_patient1)\n",
    "#\n",
    "#split_2 = int(test_size*num_patient)\n",
    "#split1_2 = int(test_size*num_patient1)\n",
    "#train_folder = folder_name[split_2:] + folder1_name[split1_2:]\n",
    "#valid_folder = folder_name[:split] + folder1_name[:split1]\n",
    "#print(split1, split1_2)\n",
    "##test_folder = folder_name[split:split_2] + folder1_name[split1:split1_2]\n",
    "#test_folder = folder1_name[split1:split1_2]\n",
    "#class0_path = []\n",
    "#for x in test_folder:\n",
    "#    #print(x)\n",
    "#    class1 = glob.glob(x + '/1/*dcm')\n",
    "#    class0 = glob.glob(x + '/0/*dcm')\n",
    "#    for i in class0:\n",
    "#        class0_path.append(i)\n",
    "#patient = ['/home/mel/PE_research/PE100/PE_lung/NCKU/07685947', '/home/mel/PE_research/PE100/PE_lung/NCKU/17923011', '/home/mel/PE_research/PE100/PE_lung/NCKU/01006789', '/home/mel/PE_research/PE100/PE_lung/NCKU/07424280', '/home/mel/PE_research/PE100/PE_lung/NCKU/19284496', '/home/mel/PE_research/PE100/PE_lung/NCKU/19160682', '/home/mel/PE_research/PE100/PE_lung/NCKU/06552091', '/home/mel/PE_research/PE100/PE_lung/open/PAT004', '/home/mel/PE_research/PE100/PE_lung/open/PAT011', '/home/mel/PE_research/PE100/PE_lung/open/PAT017']\n",
    "#patient = ['/home/mel/PE_research/PE100/non_PE/NCKU/01585175', '/home/mel/PE_research/PE100/non_PE/NCKU/18180554', '/home/mel/PE_research/PE100/non_PE/NCKU/05635111', '/home/mel/PE_research/PE100/non_PE/NCKU/19325176', '/home/mel/PE_research/PE100/non_PE/NCKU/11624858', '/home/mel/PE_research/PE100/non_PE/NCKU/17276749', '/home/mel/PE_research/PE100/non_PE/NCKU/14896060', '/home/mel/PE_research/PE100/non_PE/NCKU/03324841', '/home/mel/PE_research/PE100/non_PE/NCKU/01043033', '/home/mel/PE_research/PE100/non_PE/NCKU/07534808']\n",
    "patient = ['/home/ubuntu/Andrew/lung_datatset/test/noPE/19743272/*']\n",
    "\n",
    "path = []\n",
    "\n",
    "for p in patient:\n",
    "\n",
    "    path += list(glob.glob(p +'*dcm'))\n",
    "\n",
    "grad_cam = GradCam(model = Net, \\\n",
    "\t\t\t\ttarget_layer_names = ['layer8']) \n",
    "for i in path:\n",
    "    print(i)\n",
    "    img = pydicom.dcmread(i).pixel_array\n",
    "    img[img>1624] = 1624\n",
    "    input = np.float32(img/812)-1\n",
    "    img = np.float32(img) / 1624\n",
    "    \n",
    "    input = preprocess_image(input)\n",
    "    # If None, returns the map for the highest scoring category.\n",
    "    # Otherwise, targets the requested index.\n",
    "    target_index = None \n",
    "    mask = grad_cam(input, target_index)\n",
    "    input = input.to(device)\n",
    "    output = Net(input)\n",
    "    pred = output.data.max(1, keepdim=True)[1]\n",
    "    score = F.softmax(output)\n",
    "    if pred == 1:\n",
    "        print(score)\n",
    "        img = crop_center(img, 400, 400)\n",
    "        img = torch.tensor(img).float()\n",
    "        img_rgb = img.unsqueeze_(0).repeat(3, 1, 1)    \n",
    "        show_cam_on_image(img_rgb, mask, i, pred)\n",
    "    \n",
    "    #gb_model = GuidedBackpropReLUModel(model = Net)\n",
    "    #gb = gb_model(input, index=target_index)\n",
    "    ##utils.save_image(torch.from_numpy(gb), str(num) + '_gb.jpg')    \n",
    "    #cam_mask = np.zeros(gb.shape)\n",
    "    #for i in range(0, gb.shape[0]):\n",
    "    #    cam_mask[i, :, :] = mask.transpose(1,0)    \n",
    "    #cam_gb = np.multiply(cam_mask, gb)\n",
    "        #utils.save_image(torch.from_numpy(cam_gb), str(num) + '_cam_gb.jpg')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-presentation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
